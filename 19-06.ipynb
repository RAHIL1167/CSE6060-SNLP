{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations(when two words occur together) and Ngrams(it gives sequence of any two words)\n",
    "\n",
    "Task 1: Get the famous Gettysburg Address in .txt format\n",
    "\n",
    "Task 2: Remove the stop words from this address\n",
    "\n",
    "Task 3: Extract and display Bigrams \n",
    "\n",
    "Task 4: From the bigrams, the task is to extract collocations    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Get the famous Gettysburg Address in .txt format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=open('tasks.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourscore and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
      "\n",
      "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war.\n",
      "We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. \n",
      "It is altogether fitting and proper that we should do this.\n",
      "\n",
      "But, in a larger sense, we can not dedicate-we can not consecrate-we can not hallow-this ground.\n",
      "The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. \n",
      "The world will little note, nor long remember what we say here, but it can never forget what they did here. \n",
      "It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. \n",
      "It is rather for us to be here dedicated to the great task remaining before us-that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion-that we here highly resolve that these dead shall not have died in vain-that this nation, under God, shall have a new birth of freedom-and that government of the people, by the people, for the people shall not perish from the earth.\n"
     ]
    }
   ],
   "source": [
    "print(data.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Remove the stop words from this address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#word_tokenize accepts a string as an input, not a file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''Fourscore and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
    "\n",
    "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war.\n",
    "We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. \n",
    "It is altogether fitting and proper that we should do this.\n",
    "\n",
    "But, in a larger sense, we can not dedicate-we can not consecrate-we can not hallow-this ground.\n",
    "The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. \n",
    "The world will little note, nor long remember what we say here, but it can never forget what they did here. \n",
    "It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. \n",
    "It is rather for us to be here dedicated to the great task remaining before us-that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion-that we here highly resolve that these dead shall not have died in vain-that this nation, under God, shall have a new birth of freedom-and that government of the people, by the people, for the people shall not perish from the earth.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fourscore', 'and', 'seven', 'years', 'ago', 'our', 'fathers', 'brought', 'forth', 'on', 'this', 'continent', ',', 'a', 'new', 'nation', ',', 'conceived', 'in', 'Liberty', ',', 'and', 'dedicated', 'to', 'the', 'proposition', 'that', 'all', 'men', 'are', 'created', 'equal', '.', '\\n\\n', 'Now', 'we', 'are', 'engaged', 'in', 'a', 'great', 'civil', 'war', ',', 'testing', 'whether', 'that', 'nation', ',', 'or', 'any', 'nation', 'so', 'conceived', 'and', 'so', 'dedicated', ',', 'can', 'long', 'endure', '.', 'We', 'are', 'met', 'on', 'a', 'great', 'battle', '-', 'field', 'of', 'that', 'war', '.', '\\n', 'We', 'have', 'come', 'to', 'dedicate', 'a', 'portion', 'of', 'that', 'field', ',', 'as', 'a', 'final', 'resting', 'place', 'for', 'those', 'who', 'here', 'gave', 'their', 'lives', 'that', 'that', 'nation', 'might', 'live', '.', '\\n', 'It', 'is', 'altogether', 'fitting', 'and', 'proper', 'that', 'we', 'should', 'do', 'this', '.', '\\n\\n', 'But', ',', 'in', 'a', 'larger', 'sense', ',', 'we', 'can', 'not', 'dedicate', '-', 'we', 'can', 'not', 'consecrate', '-', 'we', 'can', 'not', 'hallow', '-', 'this', 'ground', '.', '\\n', 'The', 'brave', 'men', ',', 'living', 'and', 'dead', ',', 'who', 'struggled', 'here', ',', 'have', 'consecrated', 'it', ',', 'far', 'above', 'our', 'poor', 'power', 'to', 'add', 'or', 'detract', '.', '\\n', 'The', 'world', 'will', 'little', 'note', ',', 'nor', 'long', 'remember', 'what', 'we', 'say', 'here', ',', 'but', 'it', 'can', 'never', 'forget', 'what', 'they', 'did', 'here', '.', '\\n', 'It', 'is', 'for', 'us', 'the', 'living', ',', 'rather', ',', 'to', 'be', 'dedicated', 'here', 'to', 'the', 'unfinished', 'work', 'which', 'they', 'who', 'fought', 'here', 'have', 'thus', 'far', 'so', 'nobly', 'advanced', '.', '\\n', 'It', 'is', 'rather', 'for', 'us', 'to', 'be', 'here', 'dedicated', 'to', 'the', 'great', 'task', 'remaining', 'before', 'us', '-', 'that', 'from', 'these', 'honored', 'dead', 'we', 'take', 'increased', 'devotion', 'to', 'that', 'cause', 'for', 'which', 'they', 'gave', 'the', 'last', 'full', 'measure', 'of', 'devotion', '-', 'that', 'we', 'here', 'highly', 'resolve', 'that', 'these', 'dead', 'shall', 'not', 'have', 'died', 'in', 'vain', '-', 'that', 'this', 'nation', ',', 'under', 'God', ',', 'shall', 'have', 'a', 'new', 'birth', 'of', 'freedom', '-', 'and', 'that', 'government', 'of', 'the', 'people', ',', 'by', 'the', 'people', ',', 'for', 'the', 'people', 'shall', 'not', 'perish', 'from', 'the', 'earth', '.']\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "my_doc = nlp(text)\n",
    "\n",
    "# Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Create list of word tokens after removing stopwords\n",
    "filtered_sentence =[] \n",
    "\n",
    "for word in token_list:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    if lexeme.is_stop == False:\n",
    "        filtered_sentence.append(word) \n",
    "print(token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fourscore', 'seven', 'years', 'ago', 'fathers', 'brought', 'forth', 'continent', ',', 'new', 'nation', ',', 'conceived', 'Liberty', ',', 'dedicated', 'proposition', 'men', 'created', 'equal', '.', '\\n\\n', 'engaged', 'great', 'civil', 'war', ',', 'testing', 'nation', ',', 'nation', 'conceived', 'dedicated', ',', 'long', 'endure', '.', 'met', 'great', 'battle', '-', 'field', 'war', '.', '\\n', 'come', 'dedicate', 'portion', 'field', ',', 'final', 'resting', 'place', 'gave', 'lives', 'nation', 'live', '.', '\\n', 'altogether', 'fitting', 'proper', '.', '\\n\\n', ',', 'larger', 'sense', ',', 'dedicate', '-', 'consecrate', '-', 'hallow', '-', 'ground', '.', '\\n', 'brave', 'men', ',', 'living', 'dead', ',', 'struggled', ',', 'consecrated', ',', 'far', 'poor', 'power', 'add', 'detract', '.', '\\n', 'world', 'little', 'note', ',', 'long', 'remember', ',', 'forget', '.', '\\n', 'living', ',', ',', 'dedicated', 'unfinished', 'work', 'fought', 'far', 'nobly', 'advanced', '.', '\\n', 'dedicated', 'great', 'task', 'remaining', '-', 'honored', 'dead', 'increased', 'devotion', 'cause', 'gave', 'measure', 'devotion', '-', 'highly', 'resolve', 'dead', 'shall', 'died', 'vain', '-', 'nation', ',', 'God', ',', 'shall', 'new', 'birth', 'freedom', '-', 'government', 'people', ',', 'people', ',', 'people', 'shall', 'perish', 'earth', '.']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_sentence)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Extract and display Bigrams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n grams are a sequence of words...Like n words combined gives a meaning for example seven years is an example of bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Fourscore', 'seven'), ('seven', 'years'), ('years', 'ago'), ('ago', 'fathers'), ('fathers', 'brought'), ('brought', 'forth'), ('forth', 'continent'), ('continent', ','), (',', 'new'), ('new', 'nation'), ('nation', ','), (',', 'conceived'), ('conceived', 'Liberty'), ('Liberty', ','), (',', 'dedicated'), ('dedicated', 'proposition'), ('proposition', 'men'), ('men', 'created'), ('created', 'equal'), ('equal', '.'), ('.', '\\n\\n'), ('\\n\\n', 'engaged'), ('engaged', 'great'), ('great', 'civil'), ('civil', 'war'), ('war', ','), (',', 'testing'), ('testing', 'nation'), ('nation', ','), (',', 'nation'), ('nation', 'conceived'), ('conceived', 'dedicated'), ('dedicated', ','), (',', 'long'), ('long', 'endure'), ('endure', '.'), ('.', 'met'), ('met', 'great'), ('great', 'battle'), ('battle', '-'), ('-', 'field'), ('field', 'war'), ('war', '.'), ('.', '\\n'), ('\\n', 'come'), ('come', 'dedicate'), ('dedicate', 'portion'), ('portion', 'field'), ('field', ','), (',', 'final'), ('final', 'resting'), ('resting', 'place'), ('place', 'gave'), ('gave', 'lives'), ('lives', 'nation'), ('nation', 'live'), ('live', '.'), ('.', '\\n'), ('\\n', 'altogether'), ('altogether', 'fitting'), ('fitting', 'proper'), ('proper', '.'), ('.', '\\n\\n'), ('\\n\\n', ','), (',', 'larger'), ('larger', 'sense'), ('sense', ','), (',', 'dedicate'), ('dedicate', '-'), ('-', 'consecrate'), ('consecrate', '-'), ('-', 'hallow'), ('hallow', '-'), ('-', 'ground'), ('ground', '.'), ('.', '\\n'), ('\\n', 'brave'), ('brave', 'men'), ('men', ','), (',', 'living'), ('living', 'dead'), ('dead', ','), (',', 'struggled'), ('struggled', ','), (',', 'consecrated'), ('consecrated', ','), (',', 'far'), ('far', 'poor'), ('poor', 'power'), ('power', 'add'), ('add', 'detract'), ('detract', '.'), ('.', '\\n'), ('\\n', 'world'), ('world', 'little'), ('little', 'note'), ('note', ','), (',', 'long'), ('long', 'remember'), ('remember', ','), (',', 'forget'), ('forget', '.'), ('.', '\\n'), ('\\n', 'living'), ('living', ','), (',', ','), (',', 'dedicated'), ('dedicated', 'unfinished'), ('unfinished', 'work'), ('work', 'fought'), ('fought', 'far'), ('far', 'nobly'), ('nobly', 'advanced'), ('advanced', '.'), ('.', '\\n'), ('\\n', 'dedicated'), ('dedicated', 'great'), ('great', 'task'), ('task', 'remaining'), ('remaining', '-'), ('-', 'honored'), ('honored', 'dead'), ('dead', 'increased'), ('increased', 'devotion'), ('devotion', 'cause'), ('cause', 'gave'), ('gave', 'measure'), ('measure', 'devotion'), ('devotion', '-'), ('-', 'highly'), ('highly', 'resolve'), ('resolve', 'dead'), ('dead', 'shall'), ('shall', 'died'), ('died', 'vain'), ('vain', '-'), ('-', 'nation'), ('nation', ','), (',', 'God'), ('God', ','), (',', 'shall'), ('shall', 'new'), ('new', 'birth'), ('birth', 'freedom'), ('freedom', '-'), ('-', 'government'), ('government', 'people'), ('people', ','), (',', 'people'), ('people', ','), (',', 'people'), ('people', 'shall'), ('shall', 'perish'), ('perish', 'earth'), ('earth', '.')]\n"
     ]
    }
   ],
   "source": [
    "bigrm=list(nltk.bigrams(filtered_sentence))\n",
    "print(bigrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: From the bigrams, the task is to extract collocations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', '\\n'),\n",
       " ('Fourscore', 'seven'),\n",
       " ('add', 'detract'),\n",
       " ('ago', 'fathers'),\n",
       " ('altogether', 'fitting'),\n",
       " ('birth', 'freedom'),\n",
       " ('brought', 'forth'),\n",
       " ('created', 'equal'),\n",
       " ('died', 'vain'),\n",
       " ('fathers', 'brought'),\n",
       " ('final', 'resting'),\n",
       " ('fitting', 'proper'),\n",
       " ('forth', 'continent'),\n",
       " ('highly', 'resolve'),\n",
       " ('larger', 'sense')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.collocations\n",
    " \n",
    "import collections\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder \n",
    "from nltk.metrics import BigramAssocMeasures \n",
    "biagram_collocation = BigramCollocationFinder.from_words(filtered_sentence) \n",
    "biagram_collocation.nbest(BigramAssocMeasures.likelihood_ratio, 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
